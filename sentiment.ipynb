{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcXAg3dKJxRx",
        "colab_type": "code",
        "outputId": "152c0a09-7a10-44f3-841a-89a7a4311f38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJiBSpDEHhAM",
        "colab_type": "text"
      },
      "source": [
        "## Goal\n",
        "The goal of this project is to identify negative sentiment in CEO's messages based on earnings call transcripts. We know that CEOs are unlikely to report bad news outright and thus this notebook strives to understand how positive can CEO frame a negative news during earnings call?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uC5zzIOAuLdY",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G08Gf_1PKXea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "# change to path\n",
        "PATH='/content/drive/My Drive/Colab Notebooks/earnings'\n",
        "os.chdir(PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpIjTriNosRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install yfinance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlLslyW9Kcdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import re\n",
        "import json\n",
        "\n",
        "from datetime import datetime\n",
        "from pandas_datareader import data as pdr\n",
        "import yfinance as yf\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore')\n",
        "\n",
        "import spacy\n",
        "from textblob import TextBlob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IeqGzgXuMoD",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuGle_0pWtMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fn = '../crawler/fool/data.json'\n",
        "\n",
        "with open(fn) as f:\n",
        "    data = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUv600QUW72u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Inc:\n",
        "    def __init__(self, d):\n",
        "        self.name = d['name']\n",
        "        self.ticker = d['ticker']\n",
        "        self.quarter = d['quarter']\n",
        "        self.reporting_date = d['reporting_date']\n",
        "        self.conversations = d['conversations']\n",
        "        \n",
        "    def inc_name(self):\n",
        "        return self.name\n",
        "    \n",
        "    def inc_ticker(self):\n",
        "        return self.ticker\n",
        "        \n",
        "    def ceo_messages(self):\n",
        "        for i, speaker in enumerate(self.conversations):\n",
        "            if speaker.find('Executive') != -1:\n",
        "                ceo_speech = self.conversations[speaker]\n",
        "        \n",
        "        return ' '.join(chunk for chunks in ceo_speech for chunk in chunks)\n",
        "    \n",
        "    def analysts_questions(self):\n",
        "        analysts_questions = ''\n",
        "        for i, speaker in enumerate(self.conversations):\n",
        "            if speaker.find('Analyst') != -1:\n",
        "                analysts_questions = analysts_questions + d[speaker][0][0] + ' '\n",
        "                \n",
        "        return analysts_questions\n",
        "    \n",
        "    def speakers_analysts_coverage(self):\n",
        "        speakers = []\n",
        "        analysts_coverage = []\n",
        "        for i, speaker in enumerate(self.conversations):\n",
        "            splits = speaker.split('--')\n",
        "            \n",
        "            # if the speaker is not operator,\n",
        "            # get the name\n",
        "            if len(splits) > 1:\n",
        "                speaker = splits[0]\n",
        "                \n",
        "                # get only first name of speaker\n",
        "                speaker = speaker.split(' ')[0]\n",
        "                speakers += speaker.rstrip().lstrip(),\n",
        "                \n",
        "            # if the speaker has 3 titles,\n",
        "            # he or she is an analyst. Hence,\n",
        "            # get the bank name            \n",
        "            if len(splits) == 3:\n",
        "                analyst = splits[1]\n",
        "                analysts_coverage += analyst.rstrip().lstrip(),\n",
        "                \n",
        "        return speakers, analysts_coverage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTYtRG6YtF8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example = Inc(data[2])\n",
        "\n",
        "speakers, analysts_coverage = example.speakers_analysts_coverage()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wca5jQ94q1DI",
        "colab_type": "text"
      },
      "source": [
        "## Create label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S33m84H7SjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tickers = []\n",
        "\n",
        "for inc in data:\n",
        "    try:\n",
        "        ticks = inc['ticker']\n",
        "        date = inc['reporting_date']\n",
        "        \n",
        "        month = date[:3]\n",
        "        day = date[4:6].lstrip().rstrip()\n",
        "        \n",
        "        s = month + '-' + day + '-2019'\n",
        "        \n",
        "        dt = datetime.strptime('Jul-11-2019', '%b-%d-%Y').strftime('%Y-%m-%d')\n",
        "        \n",
        "        if ticks.find('NYSE') != -1 or ticks.find('NASDAQ') != -1:\n",
        "            tickers.append([ticks, dt])            \n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRSoSTQAL-qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ticker_changes = {}\n",
        "\n",
        "for t, d in tickers:\n",
        "    tick = t.split(':')[-1]\n",
        "    \n",
        "    info = pdr.get_data_yahoo(tick, start=\"2019-07-10\", end=\"2019-07-13\")\n",
        "    \n",
        "    try:\n",
        "        price_change = (info.iloc[0]['Open'] - info.iloc[-1]['Open']) / info.iloc[0]['Open']\n",
        "\n",
        "        ticker_changes[t] = price_change\n",
        "        \n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "behSNt_8H8E3",
        "colab_type": "text"
      },
      "source": [
        "If the stock price rises more than 5% in the positive direction, then the CEO is reporting positive news while falling more than 5% indicates bad news."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lJZefO0fLlK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(ticker_changes.items(),\n",
        "                  columns=['ticker', 'price_change'])\n",
        "\n",
        "df['price_change'].fillna(0, inplace=True)\n",
        "df.loc[(df['price_change'] >= -0.05) & (df['price_change'] < 0.05), 'bad'] = 0\n",
        "df.loc[df['price_change'] < -0.05, 'bad'] = 1\n",
        "df.loc[df['price_change'] >= 0.05, 'bad'] = -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYpQwS4hohEa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "de7d697f-5202-4892-b8be-568c7ee3b1b9"
      },
      "source": [
        "df['bad'].value_counts()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0.0    738\n",
              "-1.0     52\n",
              " 1.0     32\n",
              "Name: bad, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIrWlk8OqzeE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "507f5456-8b22-43bb-dcb1-f1e09755fd52"
      },
      "source": [
        "train_df = df[df['bad'] != 0]\n",
        "\n",
        "train_df.head()"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>price_change</th>\n",
              "      <th>bad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NASDAQ:PSMT</td>\n",
              "      <td>-0.052027</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NASDAQ:SLP</td>\n",
              "      <td>-0.134926</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NYSE:AIR</td>\n",
              "      <td>-0.079381</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NYSE:LNN</td>\n",
              "      <td>0.054989</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NYSE:JKS</td>\n",
              "      <td>0.082774</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ticker  price_change  bad\n",
              "3   NASDAQ:PSMT     -0.052027  1.0\n",
              "7    NASDAQ:SLP     -0.134926  1.0\n",
              "8      NYSE:AIR     -0.079381  1.0\n",
              "13     NYSE:LNN      0.054989 -1.0\n",
              "19     NYSE:JKS      0.082774 -1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myCgR05huRoe",
        "colab_type": "text"
      },
      "source": [
        "## spaCy\n",
        "Data exploration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzGusj9tZULe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4a2SWj0uYi2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt = example.ceo_messages()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5YJzvTS6rub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRs_5hBMy8Jb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6448f23a-618b-4d4a-8f36-de40af09f65a"
      },
      "source": [
        "txt"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Thank you, Sandeep. Good afternoon and good morning to everyone on the call. Thank you for joining us today. Infosys has delivered a strong quarter and I'm pleased with our overall performance as we continue to demonstrate our increasing relevance to clients. Our constant currency growth year on year for Q1 was 12.4%, which is the third consecutive quarter of double-digit growth. Our digital revenue growth was 41.9% and our digital revenue now accounts for 35.7% of our overall business. The large deal DCV was the highest ever at $2.7 billion. Our operating margin for Q1 was at 20.5%. We saw broad-based growth across our industry segments, service lines, and geographies. In constant currency year on year, our telco segment grew 22.6% and North America geography 13.5%. We continue to benefit from building deeper capabilities across our digital portfolio, especially in the areas of Experian's data analytics, cloud, SaaS, IoT, cybersecurity, AI, and machine learning. Our overall deal pipeline witnessed growth in Q1 and we can see that are winning market share in this competitive environment. There are many aspects of our strategy that came together to make these impressive first quarter results possible. I want to focus on how we are scaling our digital business with a few examples. For telecom major, we're helping to build a new digital customer experience for their clients, which bring together channels such as Alexa, mobile apps, chat bots, online, and contact centers in in omnichannel mode and provide improved customer engagement. We work with a large automotive client to help them navigate their digital transformation journey, delivering for them future-ready scalable digital hybrid cloud platforms. That is supportive of their digital workspace. We have been engaged to deliver cutting edge digital capabilities for a leading US insurance company. We are partnering with them to build a digital policy administration service leveraging our Infosys McCamish platform. We're enabling a large utility to build advanced planning and engineering systems to forecast the dynamic nature of future electricity demand, to help them plan and build their grids, and leverage green energy policies to make sure there are efficient distributed energy resources. I'm particularly pleased that we've opened another digital experience design and innovation studio, which was last month in shortage in London, where we're able to co-create digital experiences with our clients. I'm delighted to share that our employee reskilling program, Lex, our learning platform that covers nearly 100% of our employees globally, with employees already leveraging the Lex app each week to develop their skills. I also want to touch upon some external recognition we've received. Infosys has been recognized as a leader in the SAP S/4HANA services by NelsonHall, for global API strategy by the Forrester Wave, and in the public cloud infrastructure managed services area in the Gartner Magic Quadrant. Now that we see our client's confidence in us increasing with increased market share gains, we are focusing as well on operational efficiency and cost discipline. We have now completed all of our investments that we outlined last year when we started our strategic direction program. All future investments will come from within our P&L and they're not specific as one of the investments that we outlined last year. Over the coming quarters, I'm looking forward to seeing the benefits of these operational improvements reflect in our business. Given the evolution of our business outlook, we are now changing our revenue guidance. We've moved from 7.5% to 9% in constant currency to 8.5% to 10% in constant currency. We retain our margin guidance at 21% to 23% for the full year. Later on in the call, Nilanjan will share with you our new capital return policy. With that, let me hand it over to Pravin. This is Salil. To answer the question, Ed, I think part of what we see in terms of large deals is some of the investments we've made in our digital capabilities, they come together as part of a collective where clients are looking to modernize their tech landscape. Us being large incumbent players with long-standing relationships, it appears an advantage with these new capabilities combined with some of the areas that are long-standing projects and contracts for us. In addition to that, the way we looked at segmenting which sectors we go after and in part segmenting which potential competitors we should look at differentiating versus, those are techniques that have helped us. Overall, we see an increased engagement and intensity with our clients and that is helping us. However, as you know well, large deals are by design lumpy. We've been fortunate in Q3, Q4, and Q1 to have very strong large deal numbers. These numbers for the year, we're very confident about, but each quarter, as you know, could be up and down. Thanks. So, as you rightly point out, we've made the change. What we have on the balance sheet, as you know, we have some part of our buyback that still has to be completed. That will be used in this current buyback. We have plans over time to make sure our balance sheet is efficient. As we look around, we will look to see if that means doing more within the laws and regulations on buybacks for that or looking at other uses if we find small appropriate acquisitions that we can look at. On the guidance itself, the main reason was with the strength of growth in Q1, which was 12.4% year on year and then that on the back of two other quarters, Q4 and Q3 of last year and being double-digit, what we see in our pipelines, our large deal pipeline has improved from April 1 through now. That improvement and some of the wins in the quarter, all of those things put together give us a level of comfort to raise this guidance from 7.5%-9.5% now to 8.5% to 10%. In terms of specific segments, I think you shared when Pravin shared the view on segments, those are what we see across different segments. The mattering of the band -- our thought was given we are one quarter into the year as we increased the guidance, we felt it was perhaps more appropriate at this stage to narrow the band given what we were seeing. Sorry, go ahead. You had something else? I think from our perspective, we see that as a very critical parameter. It's something that we think is a function of both of the factors that you mentioned, the mix and the capability. It's something that we are working on actively. We think it's something in the immediate term, not immediately every quarter, but in the medium term, we think that can be something that can help us sustain and maybe even expand our margin outlook. Stated externally, the decoupling of the audit book that Nilanjan shared with you in terms of the quarter, the revenue, and the year on year revenue, that we've talked about. In terms of Brexit, we assume today that our business in the UK has remained reasonably in good shape. We don't see any particular change in our business mix today. We think once all of this Brexit discussion settles down, if anything, we will start to see some acceleration. We don't see any change or it's not something we've decoupled to make it something of a concern within the pipeline. The overall pipeline -- we shared the stat externally. I started to give some color earlier that from April 1 through now, we've seen a good growth in the large deals pipeline that we have. That's part of the reason why we see some potentially increased traction in the coming quarters. I think the big one which we continue to mention, which we said in our last call, first is in the increase in compilated costs over the year, which is about 210 basis points and the combination investments we have made, both in our salesforce, which we ramped up. The other one is the impact of the higher [inaudible] costs, which is the last year progressing at the 150 BPs. The offset of that has been the rupee benefit, about 40 basis points. We've got the benefit of RPP, the rate prior to that, which is about 50 basis points. And of course, our special quarter one impact, which is 80 basis points and a higher visa cost because we did not have that many visas last year. so, that's about 80 basis points. So, that gives us the overall, around 20 BPs. I think if you see the quarter on quarter, I think that's a situation which is to understand where we came from, how we ended last year, and what is our go forward plan in terms of improving our margin to hit our guidance of 21.3. Sorry, I didn't follow that. What was the question about the digital? So, to share with you, we have five broad areas within digital that we've outlined over the last year or so. A few of those areas we believe are going to start to be very large businesses and we'll see a lot of traction in those areas. One of them is the area of cloud. This is both cloud services, which are through our strategic partnerships with AWS, Azure, and Google Cloud, all with some of the SaaS leaders such as Salesforce or ServiceNow. Another very strong area for us is the area of data and analytics. Having said that, we also have strength in the other areas, for example, in the digital design and experience, in the area of cybersecurity and in the area of IoT. Each of these are seeing good traction. There's no one that stands out, but the first two I mentioned, I think we start to see good scale benefits from that as well. So, we had the couple of large deals in the stats we've shared outside. We do see a lot of what we are selling in the large deals -- Pravin shared a stat earlier -- are net new. In that sense, we feel good about how the margin profile of those deals have evolved. So, attrition, that is an area of extreme attention for us. We want to make sure that we take all the actions that we need to take to make sure this is within a level that is comfortable for our business going forward. Having said that, in Q1, as Pravin has shared, we've taken very strong measures and some of the attrition that it's in here is what we call involuntary attrition and some of the attrition in this stat is also for individuals who leave to go for graduate school or higher education. That is somewhat seasonal. If you look at our attrition stat, it takes all of our businesses into account. It's not just the IT services attrition. So, if you look at the attrition we are focused on, we have a lot of measures we've put in place to start to address that, in addition to making sure there are all the hygiene factors, we're also focused on really driving the opportunity set for employees to a broader base. That includes the value connection that employees will have with us. We think over the next -- in the medium term or the next three quarters, that should start to see some impact. So, the localization work has indeed been a positive and we are delighted with the progress it's made. However, it's the first step of a very long journey and we have plans in the medium term on how we think our business model will evolve. In terms of subcons, yeah. I think it's not so much and/or it's much more than both will exist. The skillsets that we see in the market today for which we're winning, we have a tremendous capacity of those skillsets. There's always some demand which comes in where the fulfillment needs to be done on a relatively quick basis. We have some operational levers that we're putting in place, including localization as one of them that will help us to adjust the subcon usage, for example, looking at aging of subcontractors that can give us benefits again in the medium term into a margin. We are fully committed to our margin guidance. There are a lot of business situations plus and minus, but we will deliver our margin guidance. It's more with respect to the traction. The comment I made there was with respect to the traction we've seen with our digital business. To give you one example, with Microsoft, we've been named as the number one partner globally. For this year, it's a shift where our capabilities on all of their product sets from Azure to Office 365 to all of the workplace toolkit, our approach to driving that into enterprise space is something that's gaining traction. So, it's not so much taking away from another competitor. We're gaining market share in a space that's growing but our growth is higher than what the overall growth for that space is. We see similar type of traction in other elements of the [inaudible] of our digital focus. For example, we see that within some of the SaaS players. We see that in a lot of agile development work that we're doing on different toolkits. We see that even for the work we're doing for S/4HANA. So, there are different places where we start to see more and more growth through those investments or capabilities that we are building or have built over the past. Okay. So, there were several points that you shared, starting with the structural piece. We have a view on the digital addressable market and the growth rate. We love data. In the coming quarters when we have a new app for analysts. If you recall, we've shared about a $160 billion market growing at 15%. So, that's the piece that we are investing in and we see some traction. One what you talk about and what we've defined as cost services, we've not declared the growth rate, but I think the market view is available if you look at what's with third-party agencies who have a lot of data like Gartner and others. It's fair to say that market has a more challenged growth environment today. In that context, how we've developed a strategic approach, that's what we're executing to. We have a view on where this might go medium-term, but we haven't actually shared any of that externally. We think the way we are driving this, for example, the 12.4% growth in Q1, that's a good indication of what are the sorts of things possible when many things come together in a fortuitous way for us in the quarter. In terms of the attrition -- we've talked about operational efficiency and we are more and more intensely focused on involuntary attrition as well. There have been some elements of what it's done seasonally and because of higher education. When you start to strip that out, we see the attrition numbers while not improving, they're stable. So, we still have work to do to make sure they start to trend down. We would like to thank everyone for joining us today on this call. We look forward to talking to you again. Have a good weekend ahead.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEMsyCJzvEwf",
        "colab_type": "code",
        "outputId": "aabd1060-358b-4f46-a558-a0b461fde0a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sentences = list(doc.sents)\n",
        "\n",
        "len(sentences)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo171CFeGsWB",
        "colab_type": "text"
      },
      "source": [
        "Find the useful entities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BTpSypQvT1N",
        "colab_type": "code",
        "outputId": "5881b143-c0a5-4733-d835-3dd8268ea93a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        }
      },
      "source": [
        "entities = ['PERSON', 'ORG', 'NORP', 'FACILITY', 'ORG', \n",
        "            'GPE', 'LOC', 'PRODUCT', 'EVENT']\n",
        "\n",
        "for ent in doc.ents:\n",
        "    if ent.label_ in entities and ent.text not in speakers:\n",
        "        print(ent.text, ent.label_)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Infosys PERSON\n",
            "North America LOC\n",
            "Experian ORG\n",
            "SaaS ORG\n",
            "Alexa ORG\n",
            "US GPE\n",
            "Infosys McCamish NORP\n",
            "London GPE\n",
            "Lex PERSON\n",
            "Infosys ORG\n",
            "SAP S/4HANA ORG\n",
            "NelsonHall ORG\n",
            "API ORG\n",
            "Forrester ORG\n",
            "Ed PERSON\n",
            "Brexit GPE\n",
            "UK GPE\n",
            "Brexit GPE\n",
            "RPP ORG\n",
            "Azure PERSON\n",
            "Google Cloud PERSON\n",
            "SaaS ORG\n",
            "Salesforce ORG\n",
            "ServiceNow ORG\n",
            "Microsoft ORG\n",
            "Azure to Office 365 ORG\n",
            "S/4HANA PERSON\n",
            "Gartner PERSON\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYlJ8juYGurX",
        "colab_type": "text"
      },
      "source": [
        "Extract sentences that has the patterns as defined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2lxSVhAG4Wg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.matcher import PhraseMatcher, Matcher\n",
        "\n",
        "business_adj = [\n",
        "    [{\"LEMMA\": {\"IN\": [\"down\", \"up\", \"small\", \"big\",\n",
        "                       \"high\", \"low\", \"strong\", \"weak\",\n",
        "                       \"large\", \"bad\", \"solid\"]}}],\n",
        "]\n",
        "\n",
        "b_adj_matcher = Matcher(nlp.vocab)\n",
        "b_adj_matcher.add(\"BusinessAdj\", None, *business_adj)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVQF6qgVTMPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "metrics = [\n",
        "    [{\"LEMMA\": {\"IN\": [\"revenue\", \"cost\", \"margin\", \n",
        "                       \"grow\", \"profit\", \"sale\",\n",
        "                       \"guidance\"]}}], # sentence contains number?\n",
        "]\n",
        "\n",
        "\n",
        "metrics_matcher = Matcher(nlp.vocab)\n",
        "metrics_matcher.add(\"BusinessMetrics\", None, *metrics)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaeOy076GmwU",
        "colab_type": "code",
        "outputId": "5285c7fd-8ecd-47de-b47a-ee8540eee99d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for sent in doc.sents:\n",
        "    sent_to_doc = sent.as_doc()\n",
        "    \n",
        "    matches = metrics_matcher(sent_to_doc)\n",
        "    \n",
        "    if matches is not None:\n",
        "        for match_id, start, end in matches:\n",
        "            \n",
        "            keyword = sent_to_doc[start:end]\n",
        "            \n",
        "            print(\"Matched on:\", keyword)\n",
        "            \n",
        "            print(sent_to_doc)\n",
        "            \n",
        "            print('\\n')\n",
        "            \n",
        "            break                    \n",
        "    \n",
        "    matches = b_adj_matcher(sent_to_doc)\n",
        "    \n",
        "    if matches is not None:\n",
        "        for match_id, start, end in matches:\n",
        "            \n",
        "            keyword = sent_to_doc[start:end]\n",
        "            \n",
        "            for chunk in sent_to_doc.noun_chunks:\n",
        "                if keyword.text in chunk.text:\n",
        "                    \n",
        "                    print(\"Matched on:\", keyword)\n",
        "            \n",
        "                    print(sent_to_doc.text)                        \n",
        "                    \n",
        "                    print(\"Adj describing:\", chunk.text)\n",
        "\n",
        "                    print('\\n')                    "
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matched on: strong\n",
            "Infosys has delivered a strong quarter and I'm pleased with our overall performance as we continue to demonstrate our increasing relevance to clients. \n",
            "Adj describing: a strong quarter\n",
            "\n",
            "\n",
            "Matched on: revenue\n",
            "Our digital revenue growth was 41.9% and our digital revenue now accounts for 35.7% of our overall business. \n",
            "\n",
            "\n",
            "Matched on: large\n",
            "The large deal DCV was the highest ever at $2.7 billion. \n",
            "Adj describing: The large deal\n",
            "\n",
            "\n",
            "Matched on: margin\n",
            "Our operating margin for Q1 was at 20.5%. \n",
            "\n",
            "\n",
            "Matched on: grew\n",
            "In constant currency year on year, our telco segment grew 22.6% and North America geography 13.5%. \n",
            "\n",
            "\n",
            "Matched on: large\n",
            "We work with a large automotive client to help them navigate their digital transformation journey, delivering for them future-ready scalable digital hybrid cloud platforms. \n",
            "Adj describing: a large automotive client\n",
            "\n",
            "\n",
            "Matched on: large\n",
            "We're enabling a large utility to build advanced planning and engineering systems to forecast the dynamic nature of future electricity demand, to help them plan and build their grids, and leverage green energy policies to make sure there are efficient distributed energy resources. \n",
            "Adj describing: a large utility\n",
            "\n",
            "\n",
            "Matched on: cost\n",
            "Now that we see our client's confidence in us increasing with increased market share gains, we are focusing as well on operational efficiency and cost discipline. \n",
            "\n",
            "\n",
            "Matched on: revenue\n",
            "Given the evolution of our business outlook, we are now changing our revenue guidance. \n",
            "\n",
            "\n",
            "Matched on: margin\n",
            "We retain our margin guidance at 21% to 23% for the full year. \n",
            "\n",
            "\n",
            "Matched on: large\n",
            "To answer the question, Ed, I think part of what we see in terms of large deals is some of the investments we've made in our digital capabilities, they come together as part of a collective where clients are looking to modernize their tech landscape. \n",
            "Adj describing: large deals\n",
            "\n",
            "\n",
            "Matched on: large\n",
            "Us being large incumbent players with long-standing relationships, it appears an advantage with these new capabilities combined with some of the areas that are long-standing projects and contracts for us. \n",
            "Adj describing: large incumbent players\n",
            "\n",
            "\n",
            "Matched on: large\n",
            "However, as you know well, large deals are by design lumpy. \n",
            "Adj describing: large deals\n",
            "\n",
            "\n",
            "Matched on: strong\n",
            "We've been fortunate in Q3, Q4, and Q1 to have very strong large deal numbers. \n",
            "Adj describing: very strong large deal numbers\n",
            "\n",
            "\n",
            "Matched on: large\n",
            "We've been fortunate in Q3, Q4, and Q1 to have very strong large deal numbers. \n",
            "Adj describing: very strong large deal numbers\n",
            "\n",
            "\n",
            "Matched on: small\n",
            "As we look around, we will look to see if that means doing more within the laws and regulations on buybacks for that or looking at other uses if we find small appropriate acquisitions that we can look at. \n",
            "Adj describing: small appropriate acquisitions\n",
            "\n",
            "\n",
            "Matched on: large\n",
            "and then that on the back of two other quarters, Q4 and Q3 of last year and being double-digit, what we see in our pipelines, our large deal pipeline has improved from April 1 through now. \n",
            "Adj describing: our large deal pipeline\n",
            "\n",
            "\n",
            "Matched on: margin\n",
            "We think it's something in the immediate term, not immediately every quarter, but in the medium term, we think that can be something that can help us sustain and maybe even expand our margin outlook. \n",
            "\n",
            "\n",
            "Matched on: revenue\n",
            "Stated externally, the decoupling of the audit book that Nilanjan shared with you in terms of the quarter, the revenue, and the year on year revenue, that we've talked about. \n",
            "\n",
            "\n",
            "Matched on: large\n",
            "I started to give some color earlier that from April 1 through now, we've seen a good growth in the large deals pipeline that we have. \n",
            "Adj describing: the large deals pipeline\n",
            "\n",
            "\n",
            "Matched on: costs\n",
            "I think the big one which we continue to mention, which we said in our last call, first is in the increase in compilated costs over the year, which is about 210 basis points and the combination investments we have made, both in our salesforce, which we ramped up. \n",
            "\n",
            "\n",
            "Matched on: big\n",
            "I think the big one which we continue to mention, which we said in our last call, first is in the increase in compilated costs over the year, which is about 210 basis points and the combination investments we have made, both in our salesforce, which we ramped up. \n",
            "Adj describing: the big one\n",
            "\n",
            "\n",
            "Matched on: costs\n",
            "The other one is the impact of the higher [inaudible] costs, which is the last year progressing at the 150 BPs. \n",
            "\n",
            "\n",
            "Matched on: higher\n",
            "The other one is the impact of the higher [inaudible] costs, which is the last year progressing at the 150 BPs. \n",
            "Adj describing: the higher [inaudible] costs\n",
            "\n",
            "\n",
            "Matched on: cost\n",
            "And of course, our special quarter one impact, which is 80 basis points and a higher visa cost because we did not have that many visas last year. \n",
            "\n",
            "\n",
            "Matched on: higher\n",
            "And of course, our special quarter one impact, which is 80 basis points and a higher visa cost because we did not have that many visas last year. \n",
            "Adj describing: a higher visa cost\n",
            "\n",
            "\n",
            "Matched on: margin\n",
            "I think if you see the quarter on quarter, I think that's a situation which is to understand where we came from, how we ended last year, and what is our go forward plan in terms of improving our margin to hit our guidance of 21.3. \n",
            "\n",
            "\n",
            "Matched on: large\n",
            "A few of those areas we believe are going to start to be very large businesses \n",
            "Adj describing: very large businesses\n",
            "\n",
            "\n",
            "Matched on: strong\n",
            "Another very strong area for us is the area of data and analytics. \n",
            "Adj describing: Another very strong area\n",
            "\n",
            "\n",
            "Matched on: large\n",
            "So, we had the couple of large deals in the stats we've shared outside. \n",
            "Adj describing: large deals\n",
            "\n",
            "\n",
            "Matched on: large\n",
            "We do see a lot of what we are selling in the large deals -- Pravin shared a stat earlier -- are net new. \n",
            "Adj describing: the large deals\n",
            "\n",
            "\n",
            "Matched on: margin\n",
            "In that sense, we feel good about how the margin profile of those deals have evolved. \n",
            "\n",
            "\n",
            "Matched on: strong\n",
            "Having said that, in Q1, as Pravin has shared, we've taken very strong measures and some of the attrition that it's in here is what we call involuntary attrition and some of the attrition in this stat is also for individuals who leave to go for graduate school or higher education. \n",
            "Adj describing: very strong measures\n",
            "\n",
            "\n",
            "Matched on: higher\n",
            "Having said that, in Q1, as Pravin has shared, we've taken very strong measures and some of the attrition that it's in here is what we call involuntary attrition and some of the attrition in this stat is also for individuals who leave to go for graduate school or higher education. \n",
            "Adj describing: higher education\n",
            "\n",
            "\n",
            "Matched on: margin\n",
            "We have some operational levers that we're putting in place, including localization as one of them that will help us to adjust the subcon usage, for example, looking at aging of subcontractors that can give us benefits again in the medium term into a margin. \n",
            "\n",
            "\n",
            "Matched on: margin\n",
            "We are fully committed to our margin guidance. \n",
            "\n",
            "\n",
            "Matched on: margin\n",
            "There are a lot of business situations plus and minus, but we will deliver our margin guidance. \n",
            "\n",
            "\n",
            "Matched on: growing\n",
            "We're gaining market share in a space that's growing but our growth is higher than what the overall growth for that space is. \n",
            "\n",
            "\n",
            "Matched on: growing\n",
            "If you recall, we've shared about a $160 billion market growing at 15%. \n",
            "\n",
            "\n",
            "Matched on: cost\n",
            "One what you talk about and what we've defined as cost services, we've not declared the growth rate, but I think the market view is available if you look at what's with third-party agencies who have a lot of data like Gartner and others. \n",
            "\n",
            "\n",
            "Matched on: higher\n",
            "There have been some elements of what it's done seasonally and because of higher education. \n",
            "Adj describing: higher education\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzuNYSs1As_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t1 = 'Another very strong area for us is the area of data and analytics.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1py5UIjvT4G",
        "colab_type": "code",
        "outputId": "81ef80d0-eb28-49d5-ea48-08e9fd37098c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        }
      },
      "source": [
        "doc = nlp(t1)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.tag_, token.dep_)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Another DET DT det\n",
            "very ADV RB advmod\n",
            "strong ADJ JJ amod\n",
            "area NOUN NN nsubj\n",
            "for ADP IN prep\n",
            "us PRON PRP pobj\n",
            "is VERB VBZ ROOT\n",
            "the DET DT det\n",
            "area NOUN NN attr\n",
            "of ADP IN prep\n",
            "data NOUN NNS pobj\n",
            "and CCONJ CC cc\n",
            "analytics NOUN NNS conj\n",
            ". PUNCT . punct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t2yUOPK1BpY",
        "colab_type": "text"
      },
      "source": [
        "Creating data for `train_df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBug0KdovT6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compile_business_sents(doc):\n",
        "    keep = ''\n",
        "    \n",
        "    for sent in doc.sents:\n",
        "        sent_to_doc = sent.as_doc()\n",
        "\n",
        "        matches = metrics_matcher(sent_to_doc)\n",
        "\n",
        "        if matches is not None:\n",
        "            for match_id, start, end in matches:\n",
        "\n",
        "                keep = keep + sent_to_doc.text\n",
        "\n",
        "                break                    \n",
        "\n",
        "        matches = b_adj_matcher(sent_to_doc)\n",
        "\n",
        "        if matches is not None:\n",
        "            for match_id, start, end in matches:\n",
        "\n",
        "                keyword = sent_to_doc[start:end]\n",
        "\n",
        "                for chunk in sent_to_doc.noun_chunks:\n",
        "                    if keyword.text in chunk.text:\n",
        "\n",
        "                        keep = keep + sent_to_doc.text\n",
        "                        \n",
        "    return keep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeRC7Jggu6P6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analyze = train_df['ticker'].tolist()\n",
        "\n",
        "for inc in data:\n",
        "    try:\n",
        "        example = Inc(inc)    \n",
        "        if example.inc_ticker() in analyze:\n",
        "            txt = example.ceo_messages()\n",
        "            doc = nlp(txt)\n",
        "            train_df.loc[train_df['ticker'] == example.inc_ticker(), 'ceo_msgs'] = compile_business_sents(doc)\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaeAJzl3w9H4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = train_df[~train_df['ceo_msgs'].isna()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrKqW3xFyVhN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "ce268dd6-309a-45a4-95f2-547f1f3ca6fb"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ticker</th>\n",
              "      <th>price_change</th>\n",
              "      <th>bad</th>\n",
              "      <th>ceo_msgs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NASDAQ:PSMT</td>\n",
              "      <td>-0.052027</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Since our last call, we've been quite busy wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NASDAQ:SLP</td>\n",
              "      <td>-0.134926</td>\n",
              "      <td>1.0</td>\n",
              "      <td>This was a very strong quarter for Simulations...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>NYSE:AIR</td>\n",
              "      <td>-0.079381</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Our sales for the full year were up 17% from $...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NYSE:LNN</td>\n",
              "      <td>0.054989</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>The ag market conditions this past quarter con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>NYSE:JKS</td>\n",
              "      <td>0.082774</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>Total revenues were $867 (ph) million, an incr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ticker  ...                                           ceo_msgs\n",
              "3   NASDAQ:PSMT  ...  Since our last call, we've been quite busy wit...\n",
              "7    NASDAQ:SLP  ...  This was a very strong quarter for Simulations...\n",
              "8      NYSE:AIR  ...  Our sales for the full year were up 17% from $...\n",
              "13     NYSE:LNN  ...  The ag market conditions this past quarter con...\n",
              "19     NYSE:JKS  ...  Total revenues were $867 (ph) million, an incr...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9iXJ_VByRPj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6ed382c8-7d6a-41a2-ccb3-c0a79772e47b"
      },
      "source": [
        "train_df['bad'].value_counts()"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.0    50\n",
              " 1.0    31\n",
              "Name: bad, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4I2MQiR2MJz",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "DistilBERT.\n",
        "\n",
        "https://github.com/huggingface/pytorch-transformers/tree/master/examples/distillation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us-q7TRS2OWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNE15gj7GwIF",
        "colab_type": "text"
      },
      "source": [
        "## To be continued..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LQarOTO2Jid",
        "colab_type": "text"
      },
      "source": [
        "Rule-base matching.\n",
        "\n",
        "https://github.com/pmbaumgartner/binder-notebooks/blob/master/rule-based-matching-with-spacy-matcher.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RThGywDv16mu",
        "colab_type": "text"
      },
      "source": [
        "Entity recognizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJEAUFfMGxTh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for chunk in doc.noun_chunks:\n",
        "#     print(chunk.root.text)\n",
        "\n",
        "# from spacy.pipeline import EntityRecognizer\n",
        "\n",
        "# ner = EntityRecognizer(nlp.vocab)\n",
        "\n",
        "# processed = ner(doc)\n",
        "\n",
        "# processed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEIIleB8uTUA",
        "colab_type": "text"
      },
      "source": [
        "TextBlob for sentiment analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t013vEga6wsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# testimonial = TextBlob(\"Maybe first off on some fundamentals for the full year, it looks like your film release number was pretty good but your revenues were down.\")\n",
        "# testimonial.sentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmm2del88T3B",
        "colab_type": "text"
      },
      "source": [
        "## Ideas\n",
        "1. Get CEO's text and do sentiment analysis\n",
        "2. Extract descriptive words of a business, e.g., down, up, small, big, high, low, strong...\n",
        "3. Extract financial keywords, e.g, revenue, cost, margin, growth...\n",
        "4. Extract change in intonation, e.g., but.\n",
        "5. Extract superlatives.\n",
        "6. Extract customers, relationships.\n",
        "7. Extract investments, acquisitions.\n",
        "8. Extract %.\n",
        "9. ESG: sustainability, environment, regulatory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdnLtVtEl_m9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fundamentals, metrics\n",
        "# revenue, guidance\n",
        "# down, up, small, big, raise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlkOgkzRpFd3",
        "colab_type": "text"
      },
      "source": [
        "## Case study\n",
        "1. NKE\n",
        "> Keywords: opportunity, geography, accelerated, long-term, inventory, risk, volatility, customer, digits, double-digits, triple, focus, deliver, accelerate, brand, distribution, members, launch\n",
        "\n",
        "2. DPZ\n",
        "> Keywords: same store sales performance, long-term growth, data, service, shrink, technology, franchise, volume-driven retail sales, strong unit economics and franchisee, priorities, international, market share, pricing and promotional, partners,  \n",
        "\n",
        "3. WMT\n",
        "> Keywords: market share, guidance, ahead, partnership, omni-channel,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKemcMNepJ5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}